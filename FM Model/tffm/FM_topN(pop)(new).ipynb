{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as sp\n",
    "from tffm import TFFMClassifier\n",
    "from tffm import TFFMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "dir_ = '../../HPCF/us/test_0.8/data/'\n",
    "file_name = 'normalized_to_rating_filter_track_5_user_100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 54969\n"
     ]
    }
   ],
   "source": [
    "# Note that x is a 2D numpy array, \n",
    "# x[i, :] contains the user-item pair, and y[i] is the corresponding rating.\n",
    "\n",
    "df = pd.read_pickle(os.path.join(dir_, file_name[:-3] + 'pkl'))\n",
    "df_train = pd.read_pickle(os.path.join(dir_, 'train_' + file_name[:-3] + 'pkl'))\n",
    "train_y = np.loadtxt(os.path.join(dir_, 'train_y_' + file_name[:-3] + 'csv'), delimiter=',')\n",
    "\n",
    "\n",
    "num_users = len(df['uid'].unique())\n",
    "num_tracks = len(df['tid'].unique())\n",
    "print(num_users, num_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tid start position : 220\n",
      "Tag start position : 55189\n",
      "Length of vector : 55190\n",
      "----------------------------------------\n",
      "Number of unique users : 220\n",
      "Number of unique tracks : 54969\n"
     ]
    }
   ],
   "source": [
    "unique_users = len(df['uid'].unique())\n",
    "unique_tracks = len(df['tid'].unique())\n",
    "l = unique_users + unique_tracks + 1\n",
    "tid_start = unique_users\n",
    "tag_start = unique_users + unique_tracks\n",
    "print ('Tid start position : ' + str(tid_start))\n",
    "print ('Tag start position : ' + str(tag_start))\n",
    "print ('Length of vector : ' + str(l))\n",
    "print('----------------------------------------')\n",
    "print ('Number of unique users : ' + str(unique_users))\n",
    "print ('Number of unique tracks : ' + str(unique_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = {}\n",
    "for i in df['tid'].unique():\n",
    "    pop[i] = len(df[df['tid']==i])/unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec8a6434d5a433e989dca8ffd4e482a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=561889.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pop\n",
    "i = 0\n",
    "v = []\n",
    "sp_rows = []\n",
    "sp_cols = []\n",
    "for index, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(row['uid'])\n",
    "    v.append(1)\n",
    "    \n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(tid_start + row['tid'])\n",
    "    v.append(1)\n",
    "\n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(tag_start)\n",
    "    v.append(pop[row['tid']])\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "train_x = sp.csr_matrix((v, (sp_rows, sp_cols)), shape=(len(df_train), l), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids = []\n",
    "for i in range(unique_tracks):\n",
    "    track_ids.append(i)\n",
    "\n",
    "all_tracks = pd.DataFrame()\n",
    "all_tracks['tid'] = track_ids\n",
    "all_tracks['count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e5f5d967934997bbd4bb379bee539c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=220.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "for i in tqdm(range(unique_users)):\n",
    "    user = df_train[df_train['uid']==i]\n",
    "    top_n = all_tracks.set_index('tid').add(user.set_index('tid'), fill_value=0).reset_index()\n",
    "    top_n = top_n[top_n['count']==0]\n",
    "    top_n['uid'] = i\n",
    "    top_n = top_n[['uid', 'tid']]\n",
    "    top_n = top_n.values.tolist()\n",
    "    x_test.extend(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7006cd37b2de40c694c169751cd21850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11531291.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "v = []\n",
    "sp_rows = []\n",
    "sp_cols = []\n",
    "for row in tqdm(x_test):\n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(row[0])\n",
    "    v.append(1)\n",
    "    \n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(tid_start + row[1])\n",
    "    v.append(1)\n",
    "    \n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(tag_start)\n",
    "    v.append(pop[row[1]])\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = sp.csr_matrix((v, (sp_rows, sp_cols)), shape=(len(x_test), l), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11531291x55190 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 34593873 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 223)\t1.0\n",
      "  (0, 55189)\t0.06818181818181818\n"
     ]
    }
   ],
   "source": [
    "print(test_x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:122: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:123: The name tf.verify_tensor_all_finite is deprecated. Please use tf.compat.v1.verify_tensor_all_finite instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:127: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:134: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/utils.py:145: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:229: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:230: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:231: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.26epoch/s]"
     ]
    }
   ],
   "source": [
    "order = 3\n",
    "model = TFFMRegressor(\n",
    "    order=order, \n",
    "    rank=10, \n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.0001), \n",
    "    n_epochs=10, \n",
    "    batch_size=16384,\n",
    "    init_std=0.00001,\n",
    "    reg=0.0001,\n",
    "    input_type='sparse'\n",
    ")\n",
    "model.fit(train_x, train_y, show_progress=True)\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(x_test, columns=['uid', 'tid'])\n",
    "df2.insert(2, 'rating', predictions, False) \n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_pickle(os.path.join('../data/sp_matrix_pop(new)', 'topN_pred_' + file_name[:-3] + 'pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
