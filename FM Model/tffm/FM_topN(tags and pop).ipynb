{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as sp\n",
    "from tffm import TFFMClassifier\n",
    "from tffm import TFFMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "dir_ = '../data/'\n",
    "folder = 'sp_matrix_tag_pop'\n",
    "file_name = 'normalized_to_rating_filter_track_5_user_50.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(dir_, folder, 'pop_d_' + file_name))\n",
    "train = pd.read_pickle(os.path.join(dir_, folder, 'train_' + file_name))\n",
    "train_ = train[['uid', 'tid', 'rating', 'count','pop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = sp.load_npz(os.path.join(dir_, folder, 'pop_d_train_x_' + file_name + '.npz'))\n",
    "train_y = np.loadtxt(os.path.join(dir_, folder, 'train_y_' + file_name[:-3] + 'csv'), delimiter=',')\n",
    "test_x_sp = sp.load_npz(os.path.join(dir_, folder, 'pop_d_test_x_' + file_name + '.npz'))\n",
    "test_y_sp = np.loadtxt(os.path.join(dir_, folder, 'test_y_' + file_name[:-3] + 'csv'), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((362677, 39375), 362677, (90670, 39375), 90670)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, len(train_y), test_x_sp.shape, len(test_y_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tid start position : 218\n",
      "Tag start position : 39355\n",
      "Length of vector : 39375\n",
      "----------------------------------------\n",
      "Number of unique users : 218\n",
      "Number of unique tracks : 39137\n"
     ]
    }
   ],
   "source": [
    "unique_users = len(df['uid'].unique())\n",
    "unique_tracks = len(df['tid'].unique())\n",
    "l = unique_users + unique_tracks + 19 + 1\n",
    "tid_start = unique_users\n",
    "tag_start = unique_users + unique_tracks\n",
    "pop_start = unique_users + unique_tracks + 19\n",
    "print ('Tid start position : ' + str(tid_start))\n",
    "print ('Tag start position : ' + str(tag_start))\n",
    "print ('Length of vector : ' + str(l))\n",
    "print('----------------------------------------')\n",
    "print ('Number of unique users : ' + str(unique_users))\n",
    "print ('Number of unique tracks : ' + str(unique_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids = []\n",
    "for i in range(unique_tracks):\n",
    "    track_ids.append(i)\n",
    "\n",
    "all_tracks = pd.DataFrame()\n",
    "all_tracks['tid'] = track_ids\n",
    "all_tracks['count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29204881f444b5b8508e385be8adfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "for i in tqdm(range(unique_users)):\n",
    "    user = train_[train_['uid']==i]\n",
    "    top_n = all_tracks.set_index('tid').add(user.set_index('tid'), fill_value=0).reset_index()\n",
    "    top_n = top_n[top_n['count']==0]\n",
    "    top_n['uid'] = i\n",
    "    top_n = top_n[['uid', 'tid']]\n",
    "    top_n = top_n.values.tolist()\n",
    "    x_test.extend(top_n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ab3aada24044e78f4a171297938b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8169189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "v = []\n",
    "sp_rows = []\n",
    "sp_cols = []\n",
    "for row in tqdm(x_test):\n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(row[0])\n",
    "    v.append(1)\n",
    "    \n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(tid_start + row[1])\n",
    "    v.append(1)\n",
    "    \n",
    "    t = df[df['tid']==row[1]].reset_index()\n",
    "    tags = t['tags'].iloc[0]\n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(tag_start + tags)\n",
    "    v.append(1)\n",
    "    \n",
    "    pop = t['pop'].iloc[0]\n",
    "    sp_rows.append(i)\n",
    "    sp_cols.append(pop_start)\n",
    "    v.append(pop)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "test_x = sp.csr_matrix((v, (sp_rows, sp_cols)), shape=(len(x_test), l), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(os.path.join(dir_, folder, 'pop_d_topN_test_x_' + file_name), test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = sp.load_npz(os.path.join(dir_, folder, 'topN_test_x_' + file_name + '.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 232)\t1.0\n",
      "  (0, 39356)\t1.0\n",
      "  (0, 39374)\t6.0\n"
     ]
    }
   ],
   "source": [
    "print(test_x[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:122: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:123: The name tf.verify_tensor_all_finite is deprecated. Please use tf.compat.v1.verify_tensor_all_finite instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:127: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:134: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/utils.py:145: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/fm/lib/python3.6/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:229: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:230: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/fm/lib/python3.6/site-packages/tffm/core.py:231: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.10s/epoch]\n"
     ]
    }
   ],
   "source": [
    "order = 4\n",
    "model = TFFMRegressor(\n",
    "    order=order, \n",
    "    rank=10, \n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.00001), \n",
    "    n_epochs=10, \n",
    "    batch_size=16384,\n",
    "    init_std=0.000001,\n",
    "    reg=0.0001,\n",
    "    input_type='sparse'\n",
    ")\n",
    "model.fit(train_x, train_y, show_progress=True)\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8169189,\n",
       " array([0.07101551, 0.023108  , 0.14877048, ..., 0.02066167, 0.02337948,\n",
       "        0.0207149 ], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1e2aefdc0495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(x_test, columns=['uid', 'tid'])\n",
    "df2.insert(2, 'rating', predictions, False) \n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_pickle(os.path.join(dir_, folder, 'pop_d_topN_pred_' + file_name[:-3] + 'pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x_sp)\n",
    "print('RMSE: {}'.format(math.sqrt(mean_squared_error(test_y_sp, predictions))))\n",
    "print('MAE: {}'.format(mean_absolute_error(test_y_sp, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_x)\n",
    "print('RMSE: {}'.format(math.sqrt(mean_squared_error(train_y, predictions))))\n",
    "print('MAE: {}'.format(mean_absolute_error(train_y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(os.path.join(dir_, folder, 'test_' + file_name[:-3] + 'pkl'))\n",
    "test.sort_values(by=['uid','tid'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = len(predictions['uid'].unique())\n",
    "num_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal Recommendation\n",
    "n=100\n",
    "top_n_lists = []\n",
    "\n",
    "for i in tqdm(range(num_user)):\n",
    "    prediction = predictions[predictions['uid'] == i]\n",
    "    prediction = prediction.sort_values(by=['rating'],  ascending=False)\n",
    "    prediction = prediction[:n]\n",
    "#     print(prediction)\n",
    "    top_n_list = []\n",
    "    for _, row in prediction.iterrows():\n",
    "        top_n_list.append(row[1])\n",
    "#     print(top_n_list)\n",
    "    top_n_lists.append(top_n_list)\n",
    "\n",
    "evaluation = []\n",
    "satisfication = 0\n",
    "for i in tqdm(range(num_user)):\n",
    "    top_n_list = top_n_lists[i]\n",
    "    precision = 0\n",
    "    for j in top_n_list:\n",
    "        p = test[test['uid'] == i]\n",
    "        p = p[p['tid']==j]\n",
    "        if len(p) > 0:\n",
    "            precision += 1\n",
    "    satisfication += precision / n\n",
    "    evaluation.append(precision)\n",
    "#     print(precision, satisfication)\n",
    "print(satisfication/num_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(by=['uid','tid'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
