{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tqdm\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from numpy import count_nonzero\n",
    "\n",
    "dir_ = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75, 3.5 , 4.75, ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.5 , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.loadtxt(os.path.join(dir_, 'rating_matrix.csv'), delimiter=',')\n",
    "pd_train = pd.read_pickle(os.path.join(dir_, 'train_normalized_to_rating_filter_track_20_user_100.pkl'))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 39088\n"
     ]
    }
   ],
   "source": [
    "num_user = len(train)\n",
    "num_track = len(train[0])\n",
    "print(num_user, num_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(u1_index, u2_index):\n",
    "        result = 0.0\n",
    "        user1_data = train[u1_index]\n",
    "        user2_data = train[u2_index]\n",
    "\n",
    "        rx_avg = user_average_rating(user1_data)\n",
    "        ry_avg = user_average_rating(user2_data)\n",
    "        sxy = common_items(user1_data, user2_data)\n",
    "\n",
    "        top_result = 0.0\n",
    "        bottom_left_result = 0.0\n",
    "        bottom_right_result = 0.0\n",
    "        for item in sxy:\n",
    "            rxs = user1_data[item]\n",
    "            rys = user2_data[item]\n",
    "\n",
    "            top_result += (rxs - rx_avg)*(rys - ry_avg)\n",
    "            bottom_left_result += pow((rxs - rx_avg), 2)\n",
    "            bottom_right_result += pow((rys - ry_avg), 2)\n",
    "        bottom_left_result = math.sqrt(bottom_left_result)\n",
    "        bottom_right_result = math.sqrt(bottom_right_result)\n",
    "        \n",
    "        ################################################################\n",
    "        if (bottom_left_result * bottom_right_result) == 0:\n",
    "            return -2, -2 # dump the data\n",
    "        ################################################################\n",
    "        \n",
    "        result = top_result/(bottom_left_result * bottom_right_result)\n",
    "        return len(sxy), result\n",
    "\n",
    "def user_average_rating(u):\n",
    "    avg_rating = 0.0\n",
    "    for i in u:\n",
    "        avg_rating += i\n",
    "    avg_rating /= len(u) * 1.0\n",
    "    return avg_rating\n",
    "\n",
    "def common_items(u1, u2):\n",
    "    result = []\n",
    "    for i in range(num_track):\n",
    "        if u1[i] > 0 and u2[i] > 0:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373e8c9822e64f53915d630d8e476ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=945.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2eac7a8c419e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearson_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0msim_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'u1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'u2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'common'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pearson'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9d1d52134708>\u001b[0m in \u001b[0;36mpearson_correlation\u001b[0;34m(u1_index, u2_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrx_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_average_rating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser1_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mry_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_average_rating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser2_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0msxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser2_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9d1d52134708>\u001b[0m in \u001b[0;36muser_average_rating\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mavg_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mavg_rating\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mavg_rating\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_rating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim_table = pd.DataFrame(columns=['u1', 'u2', 'common', 'pearson']) \n",
    "for i in tqdm(range(num_user)):\n",
    "    for j in range(i+1, num_user):\n",
    "        c, p = pearson_correlation(i,j)\n",
    "        if p != -2:\n",
    "            sim_table = sim_table.append({'u1': i, 'u2': j, 'common': c, 'pearson': p}, ignore_index=True)\n",
    "            sim_table = sim_table.append({'u1': j, 'u2': i, 'common': c, 'pearson': p}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6993128968331564 0.4970825243256837\n"
     ]
    }
   ],
   "source": [
    "sim_table_ = sim_table[sim_table['common']>10]\n",
    "sim_table_ = sim_table_.sort_values(by=['pearson'],  ascending=False)\n",
    "high_similarity = sim_table_[:int(len(sim_table_)*2/10)]\n",
    "low_similarity =sim_table_[int(len(sim_table_)*8/10):]\n",
    "high_similarity_v = sim_table_.iloc[int(len(sim_table_)*2/10)]['pearson']\n",
    "low_similarity_v = sim_table_.iloc[int(len(sim_table_)*8/10)]['pearson']\n",
    "print(high_similarity_v, low_similarity_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c4df364c054a44b1d9a6ad857ab2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=935.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[930, 485, 738, 730, 491, 198],\n",
       " [96, 24, 853, 1, 450, 514],\n",
       " [810, 917, 646, 278, 154, 690],\n",
       " [397, 622, 86, 749, 820, 90],\n",
       " [213, 216, 331, 226, 125, 634],\n",
       " [170, 259, 319, 173, 174, 378],\n",
       " [492, 363, 288, 788, 939, 747],\n",
       " [606, 137, 395, 557, 612, 65],\n",
       " [486, 804, 527, 631, 400, 70],\n",
       " [203, 214, 32, 85, 569, 671],\n",
       " [841, 625, 374, 101, 25, 789],\n",
       " [47, 910, 272, 687, 522, 906],\n",
       " [863, 812, 94, 907, 670, 92],\n",
       " [317, 626, 227, 150, 401, 466],\n",
       " [534, 196, 566, 141, 682, 867],\n",
       " [809, 290, 756, 711, 408, 760],\n",
       " [677, 821, 840, 245, 133, 118],\n",
       " [200, 175, 727, 279, 740, 675],\n",
       " [221, 474, 922, 772, 803, 575],\n",
       " [315, 182, 714, 269, 584, 937],\n",
       " [326, 136, 667, 413, 434, 456],\n",
       " [335, 798, 73, 285, 183, 879],\n",
       " [659, 281, 618, 436, 838, 877],\n",
       " [237, 912, 309, 872, 899, 4],\n",
       " [379, 316, 501, 280, 589, 835],\n",
       " [778, 267, 555, 579, 562, 201],\n",
       " [652, 617, 321, 289, 674, 262],\n",
       " [733, 702, 639, 577, 82, 439],\n",
       " [126, 5, 823, 843, 53, 896],\n",
       " [819, 298, 941, 665, 454, 785],\n",
       " [880, 759, 146, 83, 668, 54],\n",
       " [479, 46, 458, 312, 359, 581],\n",
       " [734, 870, 195, 484, 926, 761],\n",
       " [873, 260, 389, 225, 109, 741],\n",
       " [533, 181, 653, 199, 218, 693],\n",
       " [637, 323, 842, 793, 536, 567],\n",
       " [56, 850, 521, 249, 231, 490],\n",
       " [782, 443, 480, 787, 852, 469],\n",
       " [131, 412, 429, 43, 240, 689],\n",
       " [708, 167, 742, 223, 537, 345],\n",
       " [451, 944, 17, 940, 495, 189],\n",
       " [45, 308, 620, 113, 129, 506],\n",
       " [822, 923, 99, 478, 250, 327],\n",
       " [846, 781, 38, 731, 22, 943],\n",
       " [525, 588, 135, 39, 535, 497],\n",
       " [929, 338, 828, 938, 630, 230],\n",
       " [438, 184, 541, 697, 422, 615],\n",
       " [654, 375, 762, 117, 351, 310],\n",
       " [811, 887, 147, 720, 0, 292],\n",
       " [418, 556, 97, 62, 67, 745],\n",
       " [608, 122, 192, 398, 547, 942],\n",
       " [564, 729, 306, 57, 737, 356],\n",
       " [132, 597, 721, 266, 87, 592],\n",
       " [624, 460, 242, 726, 614, 149],\n",
       " [420, 159, 540, 283, 728, 241],\n",
       " [9, 472, 91, 889, 780, 163],\n",
       " [36, 248, 476, 341, 813, 764],\n",
       " [593, 676, 548, 336, 505, 792],\n",
       " [235, 383, 865, 69, 886, 847],\n",
       " [705, 735, 51, 859, 698, 18],\n",
       " [517, 510, 856, 337, 362, 130],\n",
       " [916, 550, 409, 404, 561, 515],\n",
       " [19, 14, 523, 176, 833, 645],\n",
       " [746, 882, 874, 837, 598, 834],\n",
       " [427, 12, 636, 414, 261, 827],\n",
       " [339, 180, 11, 768, 166, 20],\n",
       " [114, 707, 361, 80, 528, 330],\n",
       " [437, 63, 774, 128, 868, 864],\n",
       " [77, 496, 215, 773, 920, 511],\n",
       " [493, 507, 648, 244, 300, 679],\n",
       " [399, 463, 498, 635, 628, 881],\n",
       " [168, 660, 752, 755, 647, 274],\n",
       " [143, 894, 658, 524, 560, 116],\n",
       " [124, 578, 558, 861, 295, 26],\n",
       " [72, 252, 716, 753, 911, 29],\n",
       " [410, 296, 586, 642, 50, 148],\n",
       " [172, 297, 84, 139, 367, 791],\n",
       " [251, 301, 302, 233, 800, 688]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = pd.DataFrame(columns=['uid', 'pair']) \n",
    "for i in range(num_user):\n",
    "    pair = len(high_similarity[high_similarity['u1'] == i])\n",
    "    pairs = pairs.append({'uid': i, 'pair': pair}, ignore_index=True)\n",
    "pairs = pairs.sort_values(by=['pair'],  ascending=True)\n",
    "\n",
    "groups = []\n",
    "group_size = 6\n",
    "pairs = pairs[pairs['pair'] >= (group_size-1)]\n",
    "p_status = len(pairs)\n",
    "pbar = tqdm(total=len(pairs)) \n",
    "while len(pairs) >= group_size:\n",
    "    group = []\n",
    "    uid = pairs.iloc[0]['uid']\n",
    "    pbar.update(p_status - len(pairs))\n",
    "    p_status -= (p_status - len(pairs))\n",
    "    pair = pairs.iloc[0]['pair']\n",
    "    group.append(uid)\n",
    "    if pair == (group_size-1):\n",
    "        uid = high_similarity[high_similarity['u1'] == uid]\n",
    "        for _, row in uid.iterrows():\n",
    "            group.append(int(row['u2']))\n",
    "        check_sim = True\n",
    "        for i in range(1, group_size):\n",
    "            for j in range(i+1, group_size):\n",
    "                check = high_similarity[high_similarity['u1'] == group[i]]\n",
    "                check = check[check['u2'] == group[j]]\n",
    "                if len(check) == 0:\n",
    "                    check_sim = False\n",
    "        if check_sim:\n",
    "#             print(group)\n",
    "            groups.append(group)\n",
    "            for u in group:\n",
    "                high_similarity = high_similarity[high_similarity['u1'] != u]\n",
    "                high_similarity = high_similarity[high_similarity['u2'] != u]\n",
    "        else:\n",
    "            high_similarity = high_similarity[high_similarity['u1'] != group[0]]\n",
    "            high_similarity = high_similarity[high_similarity['u2'] != group[0]]\n",
    "        pairs = pd.DataFrame(columns=['uid', 'pair']) \n",
    "        for i in range(num_user):\n",
    "            pair = len(high_similarity[high_similarity['u1'] == i])\n",
    "            pairs = pairs.append({'uid': i, 'pair': pair}, ignore_index=True)\n",
    "        pairs = pairs.sort_values(by=['pair'],  ascending=True)\n",
    "        pairs = pairs[pairs['pair'] >= (group_size-1)]\n",
    "    else:\n",
    "        uid = high_similarity[high_similarity['u1'] == uid]\n",
    "        avaliable_uid = []\n",
    "        for _, row in pairs.iterrows():\n",
    "            if len(uid[uid['u2'] == row['uid']]) > 0:\n",
    "                avaliable_uid.append(int(row['uid']))\n",
    "                \n",
    "        pointer = []\n",
    "        for i in range(group_size-1):\n",
    "            pointer.append(i)\n",
    "\n",
    "        while pointer[0] < (len(avaliable_uid) - (group_size - 1) + 2) and len(avaliable_uid) >= (group_size-1):\n",
    "            group_ = group.copy()\n",
    "            for i in range(group_size-1):\n",
    "                group_.append(avaliable_uid[pointer[i]])\n",
    "            check_sim = True\n",
    "            for i in range(1, group_size):\n",
    "                for j in range(i+1, group_size):\n",
    "                    check = high_similarity[high_similarity['u1'] == group_[i]]\n",
    "                    check = check[check['u2'] == group_[j]]\n",
    "                    if len(check) == 0:\n",
    "                        check_sim = False\n",
    "            if check_sim:\n",
    "#                 print('_', group_)\n",
    "                groups.append(group_)\n",
    "                for u in group_:\n",
    "                    high_similarity = high_similarity[high_similarity['u1'] != u]\n",
    "                    high_similarity = high_similarity[high_similarity['u2'] != u]\n",
    "                break\n",
    "            else:\n",
    "                p = 0\n",
    "                added = False\n",
    "                while not added:\n",
    "                    if (group_size-2) - p < 0:\n",
    "                        pointer[0] = (len(avaliable_uid) - (group_size - 1) + 2)\n",
    "                        break\n",
    "                    if pointer[(group_size-2) - p] < (len(avaliable_uid) - 1 - p):\n",
    "                        pointer[(group_size-2) - p] += 1\n",
    "                        while p > 0:\n",
    "                            p -= 1\n",
    "                            if (group_size-2) - p != 0:\n",
    "                                pointer[(group_size-2) - p] = pointer[(group_size-2) - p - 1] + 1\n",
    "                        added = True\n",
    "                    else:\n",
    "                        p += 1\n",
    "        if pointer[0] == (len(avaliable_uid) - (group_size - 1) + 2) or len(avaliable_uid) < (group_size-1):\n",
    "            high_similarity = high_similarity[high_similarity['u1'] != group[0]]\n",
    "            high_similarity = high_similarity[high_similarity['u2'] != group[0]]\n",
    "        pairs = pd.DataFrame(columns=['uid', 'pair']) \n",
    "        for i in range(num_user):\n",
    "            pair = len(high_similarity[high_similarity['u1']==i])\n",
    "            pairs = pairs.append({'uid': i, 'pair': pair}, ignore_index=True)\n",
    "        pairs = pairs.sort_values(by=['pair'],  ascending=True)\n",
    "        pairs = pairs[pairs['pair'] >= (group_size-1)]\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    if len(group) != group_size:\n",
    "        print('Group size error')\n",
    "    for i in range(group_size):\n",
    "        for j in range(i+1, group_size):\n",
    "            u1 = group[i]\n",
    "            u2 = group[j]\n",
    "            c, p = pearson_correlation(u1, u2)\n",
    "            if p < high_similarity_v:\n",
    "                print('Similarity error', u1, u2, p)\n",
    "user_status = np.zeros(num_user)\n",
    "for group in groups:\n",
    "    for u in group:\n",
    "        user_status[u] += 1\n",
    "for i in user_status:\n",
    "    if i > 1:\n",
    "        print('Depulicate error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '../data/groups/high/'\n",
    "np.savetxt(os.path.join(dir_, 'group_' + str(group_size)  + '.csv'), groups, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
