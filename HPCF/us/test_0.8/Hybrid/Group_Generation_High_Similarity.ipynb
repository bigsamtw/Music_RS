{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import tqdm\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from numpy import count_nonzero\n",
    "\n",
    "dir_ = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.75, 2.5 , 0.25, ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 5.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.loadtxt(os.path.join(dir_, 'rating_matrix_normalized_to_rating_filter_track_5_user_100.csv'), delimiter=',')\n",
    "pd_train = pd.read_pickle(os.path.join(dir_, 'train_normalized_to_rating_filter_track_5_user_100.pkl'))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 54969\n"
     ]
    }
   ],
   "source": [
    "num_user = len(train)\n",
    "num_track = len(train[0])\n",
    "print(num_user, num_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_correlation(u1_index, u2_index):\n",
    "        result = 0.0\n",
    "        user1_data = train[u1_index]\n",
    "        user2_data = train[u2_index]\n",
    "\n",
    "        rx_avg = user_average_rating(user1_data)\n",
    "        ry_avg = user_average_rating(user2_data)\n",
    "        sxy = common_items(user1_data, user2_data)\n",
    "\n",
    "        top_result = 0.0\n",
    "        bottom_left_result = 0.0\n",
    "        bottom_right_result = 0.0\n",
    "        for item in sxy:\n",
    "            rxs = user1_data[item]\n",
    "            rys = user2_data[item]\n",
    "\n",
    "            top_result += (rxs - rx_avg)*(rys - ry_avg)\n",
    "            bottom_left_result += pow((rxs - rx_avg), 2)\n",
    "            bottom_right_result += pow((rys - ry_avg), 2)\n",
    "        bottom_left_result = math.sqrt(bottom_left_result)\n",
    "        bottom_right_result = math.sqrt(bottom_right_result)\n",
    "        \n",
    "        ################################################################\n",
    "        if (bottom_left_result * bottom_right_result) == 0:\n",
    "            return -2, -2 # dump the data\n",
    "        ################################################################\n",
    "        \n",
    "        result = top_result/(bottom_left_result * bottom_right_result)\n",
    "        return len(sxy), result\n",
    "\n",
    "def user_average_rating(u):\n",
    "    avg_rating = 0.0\n",
    "    for i in u:\n",
    "        avg_rating += i\n",
    "    avg_rating /= len(u) * 1.0\n",
    "    return avg_rating\n",
    "\n",
    "def common_items(u1, u2):\n",
    "    result = []\n",
    "    for i in range(num_track):\n",
    "        if u1[i] > 0 and u2[i] > 0:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e9763a72ba4d509dd39d2a1a8ea651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=220.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sim_table = pd.DataFrame(columns=['u1', 'u2', 'common', 'pearson']) \n",
    "for i in tqdm(range(num_user)):\n",
    "    for j in range(i+1, num_user):\n",
    "        c, p = pearson_correlation(i,j)\n",
    "        if p != -2:\n",
    "            p = p * min(c,200) / 200\n",
    "            sim_table = sim_table.append({'u1': i, 'u2': j, 'common': c, 'pearson': p}, ignore_index=True)\n",
    "            sim_table = sim_table.append({'u1': j, 'u2': i, 'common': c, 'pearson': p}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5812300928516224 0.06318305139942057\n"
     ]
    }
   ],
   "source": [
    "# sim_table_ = sim_table[sim_table['common']>10]\n",
    "sim_table_ = sim_table.copy()\n",
    "sim_table_ = sim_table_.sort_values(by=['pearson'],  ascending=False)\n",
    "sim_table_ = sim_table_.reset_index()\n",
    "high_similarity = sim_table_[:int(len(sim_table_)*2/10)]\n",
    "low_similarity =sim_table_[int(len(sim_table_)*8/10):]\n",
    "high_similarity_v = sim_table_.iloc[int(len(sim_table_)*2/10)]['pearson']\n",
    "low_similarity_v = sim_table_.iloc[int(len(sim_table_)*8/10)]['pearson']\n",
    "print(high_similarity_v, low_similarity_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f0985e1d2d4bcd87887f99b40c5ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[21, 178, 116, 179, 72],\n",
       " [186, 60, 22, 185, 110],\n",
       " [145, 75, 74, 188, 50],\n",
       " [49, 41, 151, 61, 3],\n",
       " [20, 43, 142, 180, 52],\n",
       " [194, 158, 155, 189, 93],\n",
       " [149, 55, 171, 219, 57],\n",
       " [161, 88, 80, 19, 172],\n",
       " [205, 107, 73, 66, 124],\n",
       " [54, 7, 123, 115, 33],\n",
       " [208, 102, 169, 45, 182],\n",
       " [8, 13, 210, 79, 199],\n",
       " [2, 177, 140, 11, 202],\n",
       " [106, 213, 138, 68, 134],\n",
       " [62, 81, 0, 207, 12],\n",
       " [108, 71, 113, 173, 4],\n",
       " [89, 130, 31, 47, 164],\n",
       " [183, 193, 119, 209, 132],\n",
       " [176, 120, 64, 165, 103],\n",
       " [150, 58, 196, 77, 39],\n",
       " [214, 56, 63, 191, 126]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = pd.DataFrame(columns=['uid', 'pair']) \n",
    "for i in range(num_user):\n",
    "    pair = len(high_similarity[high_similarity['u1'] == i])\n",
    "    pairs = pairs.append({'uid': i, 'pair': pair}, ignore_index=True)\n",
    "pairs = pairs.sort_values(by=['pair'],  ascending=True)\n",
    "\n",
    "groups = []\n",
    "group_size = 5\n",
    "pairs = pairs[pairs['pair'] >= (group_size-1)]\n",
    "p_status = len(pairs)\n",
    "pbar = tqdm(total=len(pairs)) \n",
    "while len(pairs) >= group_size:\n",
    "    group = []\n",
    "    uid = pairs.iloc[0]['uid']\n",
    "    pbar.update(p_status - len(pairs))\n",
    "    p_status -= (p_status - len(pairs))\n",
    "    pair = pairs.iloc[0]['pair']\n",
    "    group.append(uid)\n",
    "    if pair == (group_size-1):\n",
    "        uid = high_similarity[high_similarity['u1'] == uid]\n",
    "        for _, row in uid.iterrows():\n",
    "            group.append(int(row['u2']))\n",
    "        check_sim = True\n",
    "        for i in range(1, group_size):\n",
    "            for j in range(i+1, group_size):\n",
    "                check = high_similarity[high_similarity['u1'] == group[i]]\n",
    "                check = check[check['u2'] == group[j]]\n",
    "                if len(check) == 0:\n",
    "                    check_sim = False\n",
    "        if check_sim:\n",
    "#             print(group)\n",
    "            groups.append(group)\n",
    "            for u in group:\n",
    "                high_similarity = high_similarity[high_similarity['u1'] != u]\n",
    "                high_similarity = high_similarity[high_similarity['u2'] != u]\n",
    "        else:\n",
    "            high_similarity = high_similarity[high_similarity['u1'] != group[0]]\n",
    "            high_similarity = high_similarity[high_similarity['u2'] != group[0]]\n",
    "        pairs = pd.DataFrame(columns=['uid', 'pair']) \n",
    "        for i in range(num_user):\n",
    "            pair = len(high_similarity[high_similarity['u1'] == i])\n",
    "            pairs = pairs.append({'uid': i, 'pair': pair}, ignore_index=True)\n",
    "        pairs = pairs.sort_values(by=['pair'],  ascending=True)\n",
    "        pairs = pairs[pairs['pair'] >= (group_size-1)]\n",
    "    else:\n",
    "        uid = high_similarity[high_similarity['u1'] == uid]\n",
    "        avaliable_uid = []\n",
    "        for _, row in pairs.iterrows():\n",
    "            if len(uid[uid['u2'] == row['uid']]) > 0:\n",
    "                avaliable_uid.append(int(row['uid']))\n",
    "                \n",
    "        pointer = []\n",
    "        for i in range(group_size-1):\n",
    "            pointer.append(i)\n",
    "\n",
    "        while pointer[0] < (len(avaliable_uid) - (group_size - 1) + 2) and len(avaliable_uid) >= (group_size-1):\n",
    "            group_ = group.copy()\n",
    "            for i in range(group_size-1):\n",
    "                group_.append(avaliable_uid[pointer[i]])\n",
    "            check_sim = True\n",
    "            for i in range(1, group_size):\n",
    "                for j in range(i+1, group_size):\n",
    "                    check = high_similarity[high_similarity['u1'] == group_[i]]\n",
    "                    check = check[check['u2'] == group_[j]]\n",
    "                    if len(check) == 0:\n",
    "                        check_sim = False\n",
    "            if check_sim:\n",
    "#                 print('_', group_)\n",
    "                groups.append(group_)\n",
    "                for u in group_:\n",
    "                    high_similarity = high_similarity[high_similarity['u1'] != u]\n",
    "                    high_similarity = high_similarity[high_similarity['u2'] != u]\n",
    "                break\n",
    "            else:\n",
    "                p = 0\n",
    "                added = False\n",
    "                while not added:\n",
    "                    if (group_size-2) - p < 0:\n",
    "                        pointer[0] = (len(avaliable_uid) - (group_size - 1) + 2)\n",
    "                        break\n",
    "                    if pointer[(group_size-2) - p] < (len(avaliable_uid) - 1 - p):\n",
    "                        pointer[(group_size-2) - p] += 1\n",
    "                        while p > 0:\n",
    "                            p -= 1\n",
    "                            if (group_size-2) - p != 0:\n",
    "                                pointer[(group_size-2) - p] = pointer[(group_size-2) - p - 1] + 1\n",
    "                        added = True\n",
    "                    else:\n",
    "                        p += 1\n",
    "        if pointer[0] == (len(avaliable_uid) - (group_size - 1) + 2) or len(avaliable_uid) < (group_size-1):\n",
    "            high_similarity = high_similarity[high_similarity['u1'] != group[0]]\n",
    "            high_similarity = high_similarity[high_similarity['u2'] != group[0]]\n",
    "        pairs = pd.DataFrame(columns=['uid', 'pair']) \n",
    "        for i in range(num_user):\n",
    "            pair = len(high_similarity[high_similarity['u1']==i])\n",
    "            pairs = pairs.append({'uid': i, 'pair': pair}, ignore_index=True)\n",
    "        pairs = pairs.sort_values(by=['pair'],  ascending=True)\n",
    "        pairs = pairs[pairs['pair'] >= (group_size-1)]\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    if len(group) != group_size:\n",
    "        print('Group size error')\n",
    "    for i in range(group_size):\n",
    "        for j in range(i+1, group_size):\n",
    "            u1 = group[i]\n",
    "            u2 = group[j]\n",
    "            c, p = pearson_correlation(u1, u2)\n",
    "            if p < high_similarity_v:\n",
    "                print('Similarity error', u1, u2, p)\n",
    "user_status = np.zeros(num_user)\n",
    "for group in groups:\n",
    "    for u in group:\n",
    "        user_status[u] += 1\n",
    "for i in user_status:\n",
    "    if i > 1:\n",
    "        print('Depulicate error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(dir_, 'groups/high/' + str(group_size)  + '.csv'), groups, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
