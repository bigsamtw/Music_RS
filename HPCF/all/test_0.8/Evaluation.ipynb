{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from numpy import count_nonzero\n",
    "from statistics import mean\n",
    "\n",
    "dir_ = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'normalized_minmax_filter_track_5_user_100.csv'\n",
    "pred_m = pd.read_pickle(os.path.join(dir_, 'prediction_svd_top_N_' + file_name[:-3] + 'pkl'))\n",
    "test_m = pd.read_pickle(os.path.join(dir_, 'test_' + file_name[:-3] + 'pkl'))\n",
    "\n",
    "file_name = 'normalized_to_rating_filter_track_5_user_100.csv'\n",
    "all_user = pd.read_pickle(os.path.join(dir_, file_name[:-3] + 'pkl'))\n",
    "pred_l = pd.read_pickle(os.path.join(dir_, 'prediction_svd_top_N_' + file_name[:-3] + 'pkl'))\n",
    "test_l = pd.read_pickle(os.path.join(dir_, 'test_' + file_name[:-3] + 'pkl'))\n",
    "\n",
    "num_user = len(pred_m['uid'].unique())\n",
    "num_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dict = {}\n",
    "for i in all_user['tid'].unique():\n",
    "    pop_dict[i] = len(all_user[all_user['tid']==i])/num_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    for i in range(len(r)):\n",
    "        r[i] = 2**r[i] -1\n",
    "    \n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, r_max, k, method=0):\n",
    "    dcg_max = dcg_at_k(r_max, k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e7311100464aac83969f5f405d08a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Personal Recommendation\n",
    "n=50\n",
    "top_n_lists_m = []\n",
    "top_n_lists_l = []\n",
    "\n",
    "for i in tqdm(range(num_user)):\n",
    "    pred = pred_m[pred_m['uid'] == i]\n",
    "    pred = pred.sort_values(by=['rating'],  ascending=False)\n",
    "    pred = pred[:n]\n",
    "    top_n_list_m = []\n",
    "    for _, row in pred.iterrows():\n",
    "        top_n_list_m.append(row[1])\n",
    "    top_n_lists_m.append(top_n_list_m)\n",
    "    \n",
    "    pred = pred_l[pred_m['uid'] == i]\n",
    "    pred = pred.sort_values(by=['rating'],  ascending=False)\n",
    "    pred = pred[:n]\n",
    "    top_n_list_l = []\n",
    "    for _, row in pred.iterrows():\n",
    "        top_n_list_l.append(row[1])\n",
    "    top_n_lists_l.append(top_n_list_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d710ce0bd3744f79a639b917c16641e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "presicion:  0.11945435466946484\n",
      "recall:  0.011246228196379228\n",
      "nDCG:  0.051742824298940955\n",
      "HitNOV 0.07228140218826283\n",
      "HitCOV 0.0021958912716495203\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "nDCG = []\n",
    "HitNOV = []\n",
    "\n",
    "test = test_m\n",
    "hits = np.zeros(len(all_user['tid'].unique()), dtype=bool)\n",
    "for i in tqdm(range(num_user)):\n",
    "    top_n_list = top_n_lists_m[i]\n",
    "    \n",
    "    hit = 0\n",
    "    nov = 0\n",
    "    truth_rating = []\n",
    "    for j in top_n_list:\n",
    "        t = test[test['uid'] == i]\n",
    "        t = t[t['tid']==j]\n",
    "        if len(t) > 0:\n",
    "            hit += 1\n",
    "            nov += (1-pop_dict[j])\n",
    "            truth_rating.append(t.iloc[0]['rating']) # For nDCG\n",
    "            hits[int(j)] = True\n",
    "        else:\n",
    "            truth_rating.append(0) # For nDCG\n",
    "    max_rating = test[test['uid']==i].sort_values(by=['rating'],  ascending=False)['rating'].values[:n]\n",
    "\n",
    "    precision.append(hit/n)\n",
    "    recall.append(hit/len(test[test['uid'] == i]))\n",
    "    nDCG.append(ndcg_at_k(truth_rating, max_rating, n, method=1))\n",
    "    HitNOV.append(nov/n)\n",
    "\n",
    "print('presicion: ', mean(precision))\n",
    "print('recall: ', mean(recall))\n",
    "print('nDCG: ', mean(nDCG))\n",
    "print('HitNOV', mean(HitNOV))\n",
    "print('HitCOV', list(hits).count(True)/len(all_user['tid'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd965193df140e89de3159345e90660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "presicion:  0.12329485834207765\n",
      "recall:  0.010897588589790062\n",
      "nDCG:  0.06855756490576671\n",
      "HitNOV 0.07534532249735468\n",
      "HitCOV 0.003154213763034138\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "nDCG = []\n",
    "HitNOV = []\n",
    "\n",
    "test = test_l\n",
    "hits = np.zeros(len(all_user['tid'].unique()), dtype=bool)\n",
    "for i in tqdm(range(num_user)):\n",
    "    top_n_list = top_n_lists_l[i]\n",
    "    \n",
    "    hit = 0\n",
    "    nov = 0\n",
    "    truth_rating = []\n",
    "    for j in top_n_list:\n",
    "        t = test[test['uid'] == i]\n",
    "        t = t[t['tid']==j]\n",
    "        if len(t) > 0:\n",
    "            hit += 1\n",
    "            nov += (1-pop_dict[j])\n",
    "            truth_rating.append(t.iloc[0]['rating']) # For nDCG\n",
    "            hits[int(j)] = True\n",
    "        else:\n",
    "            truth_rating.append(0) # For nDCG\n",
    "    max_rating = test[test['uid']==i].sort_values(by=['rating'],  ascending=False)['rating'].values[:n]\n",
    "\n",
    "    precision.append(hit/n)\n",
    "    recall.append(hit/len(test[test['uid'] == i]))\n",
    "    nDCG.append(ndcg_at_k(truth_rating, max_rating, n, method=1))\n",
    "    HitNOV.append(nov/n)\n",
    "\n",
    "print('presicion: ', mean(precision))\n",
    "print('recall: ', mean(recall))\n",
    "print('nDCG: ', mean(nDCG))\n",
    "print('HitNOV', mean(HitNOV))\n",
    "print('HitCOV', list(hits).count(True)/len(all_user['tid'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
