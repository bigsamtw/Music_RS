{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tfcf.metrics import mae\n",
    "from tfcf.metrics import rmse\n",
    "from tfcf.datasets import ml1m\n",
    "from tfcf.config import Config\n",
    "from tfcf.models.svd import SVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir_ = '../../data/'\n",
    "file_name = 'normalized_minmax_filter_track_5_user_100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2463710 2463710\n",
      "1970968 1970968 492742 492742\n"
     ]
    }
   ],
   "source": [
    "# Note that x is a 2D numpy array, \n",
    "# x[i, :] contains the user-item pair, and y[i] is the corresponding rating.\n",
    "\n",
    "df = pd.read_pickle(os.path.join(dir_, file_name[:-3] + 'pkl'))\n",
    "\n",
    "x_train = np.loadtxt(os.path.join(dir_, 'train_x_' + file_name), delimiter=',')\n",
    "y_train = np.loadtxt(os.path.join(dir_, 'train_y_' + file_name), delimiter=',')\n",
    "print(len(x_train), len(y_train))\n",
    "\n",
    "x_train, x_val = train_test_split(x_train, test_size=0.2, random_state= np.random)\n",
    "y_train, y_val = train_test_split(y_train, test_size=0.2, random_state= np.random)\n",
    "print(len(x_train), len(y_train), len(x_val), len(y_val))\n",
    "\n",
    "x_test = np.loadtxt(os.path.join(dir_, 'test_x_' + file_name), delimiter=',')\n",
    "y_test = np.loadtxt(os.path.join(dir_, 'test_y_' + file_name), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  939., 10402.],\n",
       "       [   88., 51077.],\n",
       "       [  304., 16034.],\n",
       "       ...,\n",
       "       [  673., 21943.],\n",
       "       [  273.,  7687.],\n",
       "       [  927.,  6052.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.num_users = len(df['uid'].unique())\n",
    "config.num_items = len(df['tid'].unique())\n",
    "config.min_value = df['rating'].min()\n",
    "config.max_value = df['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/han/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.4367 - mae: 0.2669 - val_rmse: 0.4374 - val_mae: 0.2678\n",
      "Epoch 2/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.4303 - mae: 0.2627 - val_rmse: 0.4391 - val_mae: 0.2694\n",
      "Epoch 3/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.4182 - mae: 0.2537 - val_rmse: 0.4428 - val_mae: 0.2732\n",
      "Epoch 4/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3987 - mae: 0.2389 - val_rmse: 0.4493 - val_mae: 0.2793\n",
      "Epoch 5/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3794 - mae: 0.2255 - val_rmse: 0.4565 - val_mae: 0.2859\n",
      "Epoch 6/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3642 - mae: 0.2161 - val_rmse: 0.4628 - val_mae: 0.2915\n",
      "Epoch 7/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3527 - mae: 0.2096 - val_rmse: 0.4683 - val_mae: 0.2961\n",
      "Epoch 8/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3439 - mae: 0.2051 - val_rmse: 0.4727 - val_mae: 0.2996\n",
      "Epoch 9/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3371 - mae: 0.2016 - val_rmse: 0.4763 - val_mae: 0.3027\n",
      "Epoch 10/10\n",
      "963/963 [==============================] - 18s 19ms/step - rmse: 0.3318 - mae: 0.1990 - val_rmse: 0.4793 - val_mae: 0.3049\n",
      "rmse: 0.4794875904971239, mae: 0.30418126312296134\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    # For SVD++ algorithm, if `dual` is True, then the dual term of items' \n",
    "    # implicit feedback will be added into the original SVD++ algorithm.\n",
    "    # model = SVDPP(config, sess, dual=False)\n",
    "    # model = SVDPP(config, sess, dual=True)\n",
    "    model = SVD(config, sess)\n",
    "    model.train(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=2048)        \n",
    "    y_pred = model.predict(x_test)\n",
    "    print('rmse: {}, mae: {}'.format(rmse(y_test, y_pred), mae(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09071007 0.20598707 0.25707743 ... 0.15305823 0.37774205 0.04582554]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred, columns=['rating'])\n",
    "df2 = pd.DataFrame(x_test, columns=['uid', 'tid'])\n",
    "df2.insert(2, 'rating', y_pred, False) \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_pickle(os.path.join(dir_, 'prediction_svd_top_N_' + file_name[:-3] + 'pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
